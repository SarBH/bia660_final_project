"BIA Advisory Services, LLC is a leading media and communications research and consulting company. For our clients, we develop and publish a vast amount of proprietary data covering the traditional and digital media industries. We sell access to a well-known data platform called BIA ADVantage™ that delivers detailed data covering nationwide and local advertising spend. In addition, BIA maintains proprietary databases on the television, radio and publishing industries that include information obtained through our internal call out team, industry surveying and publicly available government sources.As our business expands, we are seeking a Research Data Engineer to help with database administration. The new individual will take on two key roles.First, the individual will manage our research databases and help with optimizing the flow of our comprehensive data within the databases to support our different services, publication report development and daily database updates.Second, the individual will assist in the formulation of advertising revenue estimates, assist in analyzing big data sets related to the broadcasting and related industries, help with industry reports and assist with internal and client inquires.In this role, this person will support our client services team and software developers and will help manage and improve optimal data delivery across multiple projects. The person must be comfortable supporting the data needs of multiple teams, systems and products and be capable to work within different database environments.Strong communication and database and analytical skills are must haves. The right candidate will also be excited by the prospect of optimizing or even being engaged with re-designing our company’s data architecture to support our next generation of products and data initiatives.This position will report to the company’s Chief Economist.Responsibilities Include:· Build, evolve and maintain BIA’s databases and help optimize data flow to company platforms and products.· Identify, design and implement process improvements, such as automation of manual processes, enhancement of data delivery, and initiatives to support better data delivery.· Support daily and weekly initiatives to produce BIA’s Investing In publications, and maintain and update BIA's proprietary databases (i.e. Dataworld FLAG services and MAPro.)· Drive efforts to maintain and improve data quality.· Analyze and assist with managing large research data sets to help formulate advertising estimates.· Assist research needs for the analytical team.· Support client inquiries.QualificationsExperience in researching new and emerging technologies/industries.Experience in data analysis and problem solving with big data.Expert SQL or knowledge of relational databases and methods for efficiently retrieving data.Data frames and data streamingBI business intelligenceData visualization toolExperience with Excel or knowledge of spreadsheets and methods for efficiently analyzing data.Practiced PowerPoint skills or knowledge of presentation software for efficiently displaying results.Excellent verbal, written and computer communication skills with strong analytical and troubleshooting skills.BIA is located in Chantilly, VA. Remote work is supported.Job Type: Full-timeBenefits:401(k)Dental insuranceFlexible scheduleFlexible spending accountHealth insurancePaid time offSchedule:Monday to FridayCOVID-19 considerations:We are mainly a remote workforce and when we do come to the office, our team is extremely respectful of social distancing and always wear masks.Experience:Excel or spreadsheet: 1 year (Preferred)Expert SQL or knowledge of relational databases: 3 years (Preferred)Database administration: 3 years (Preferred)Database management: 3 years (Preferred)data engineering: 3 years (Preferred)Work Location:Multiple locationsFully RemoteVisa Sponsorship Potentially Available:No: Not providing sponsorship for this jobThis Job Is:A good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or moreA job for which all ages, including older job seekers, are encouraged to applyOpen to applicants who do not have a college diplomaCompany's website:www.bia.comCompany's Facebook page:https://www.facebook.com/biakelsey/Benefit Conditions:Waiting period may applyCOVID-19 Precaution(s):Remote interview processSocial distancing guidelines in placeVirtual meetings",data engineer
"Description
We are the world’s learning company with more than 24,000 employees operating in 70 countries. We combine world-class educational content and assessment,powered by services and technology, to enable more effective teaching and personalized learning at scale. We believe that wherever learning flourishes so do people.
The Data Engineer is part of a team responsible for supporting corporate and customer based reporting, as well as on-demand data needs for the organization. Under the direction of the Manager of Business Intelligence Systems, this individual will participate in the planning, design, development and implementation of solutions to address ongoing business reporting opportunities and needs.
Responsibilities
Develop impactful and accurate reports, dashboards and other data visualizations.

Communicate effectively across multiple departments and with stakeholders to review business requirements and propose solutions.

Support cross-team requirement and development efforts for multiple projects.

Maintain data integrity and ongoing quality of delivered reports.
Support ad hoc reporting as necessary for outside departments.

Identify data quality issues and work with appropriate teams to resolve them.

Document design, deployment, and operating procedures for each report.

Other duties as assigned.

Qualifications
Requirements
Proven experience with report design and ability to present data in a meaningful way using Power BI, Reporting Services and/or MS Excel

Excellent attention to detail.

Good understanding of database structures and query optimization.
Strong knowledge of SQL with experience querying large complex data models.

Experience with creation and maintenance of database objects.

Good communication skills with the ability to understand and translate user requests into technical requirements.

Strong customer service orientation.

Creativity to discover multiple solutions to business intelligence problems.
High-speed Internet access at home.

Bachelor’s degree or equivalent experience in Computer Science, Information Systems or related disciplines.

Due to the nature of this position, the applicant will need the ability to work from home or during off-hours as necessary.

Nice to have, but not necessary:
Experience with other tools in the Microsoft Business Intelligence stack (Integration Services, Analysis Services).
Familiarity with Sharepoint.

#LI-POST
Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify. All qualified applicants, including minorities, women, protected veterans, and individuals with disabilities are encouraged to apply.
Primary Location: US-NC-Durham
Other Locations US-MD-Columbia
Work Locations: US-NC-Durham-5425 Page Churchill 5425 Page Road Durham 27703
Job: Technology
Organization: Technology & Operations
Employee Status: Regular Employee
Job Type: Standard
Shift: Day Job
Job Posting: Oct 12, 2020
Job Unposting: Ongoing
Schedule: Full-time Regular
Req ID: 2008566
Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify. All qualified applicants, including minorities, women, protected veterans, and individuals with disabilities are encouraged to apply.",data engineer
"We are seeking a Jr. Data Engineer to join our technical team working on challenging data integration projects. We value innovative employees who have a sense of ownership in their work and perform well in a fast paced, collaborative team environment. You will work on a combination of exciting new projects and initiatives while also working to improve and maintain existing solutions (using cloud technologies). You will become an integral part of a fast-growing team of ETL, BI developers and analysts dedicated to the success of higher education.This position is currently fully remote due to COVID but will require in person work from office when return to work is possible. Flexible hours and partial WFH is available.Principal Responsibilities:Perform SQL development, unit testing and deployment of ETL solutionsDesign complex data workflow solutions and data models based on user requirementsDevelop ETL using open source tools and commercial solutions such as Oracle Data Integrator (ODI), Informatica.Performs design and code review functions for the development projectsMentor and coach other ETL developersResearch and recommends alternative actions to resolve problemsAnalyze trends in performance to proactively prevent problemsTroubleshoot ETL issues in real-time and diagnoses the root causeSkills needed to be successful:Understanding of data warehouse concepts and structuresExperience developing complex SQL queries and analyze data, systems integration experienceExperience with data mapping, and the ability to design and develop ETL solutionsExperience with translation of requirements into data model specificationsAbility to multi-task, ability to troubleshoot problems in real-time and diagnose the root causeDesire to join a small, growing company where the sky is the limit on opportunityAttitude of self-starter and ability to explore and find solutions with minimal supervisionRequired Experience:Candidates must have 2+ years in ETL and related experience with 1+ years leading the design and development of complex solutions.Job Type: Full-timeExperience:SQL: 1 year (Required)ETL: 1 year (Required)",data engineer
"Location: Chevy Chase, Maryland, United States

Requisition Number: 541
Position Title: Data Engineer
External Description:
Now Hiring a Data Engineer

Interested in building a large scale, modern data ecosystem as a member of a transformation focused consulting company that is working with one of the largest financial service companies in the US? Join us as we transform and modernize our clients' data environment into a robust and intelligent data ecosystem. This is a fast-moving, forward-leaning initiative to build a full featured platform which will serve as the backbone for their big data and data analytics innovations. We are looking for modern data enthusiasts who want to make a big impact, deliver great technology, and work on an exciting team. This is a remote position but must be able to commute to Chevy Chase, MD occasionally.

Profile of Success

Work in a team using cutting edge technologies to solve challenging business problems and build solutions
Interact directly with our client(s) to understand their needs and meet, or exceed their expectations by meeting delivery deadlines
Work in an agile environment with participation in daily stand-ups/scrum
Design, write, test, troubleshoot, and document data transformations
Learn new technologies and be aware of industry standards, best practices, and trends.

Required Skills

3+ years of experience working with Scala
Hands on Programming experience in Scala with Spark for ETL
Advanced SQL skills
Possess Hive skills with HiveQL.
Experience in designing efficient and robust ETL/ELT workflows, schedulers using Oozie, and event-based triggers
Big Data Experience - Experience with Ab Initio, MDM, Microstrategy, Cassandra, Hadoop, Spring Cloud
Data Operations and Security - experience with tools like Collibra, able to establish data standards and policies
Proven ability to work with clients to understand requirements and envision data ingestion solutions

Desirable Skills

Experience with Snowflake
Experience with the Azure storage technologies (Azure Data Lake, Azure SQL Data Warehouse, Azure SQL Database)
Knowledge of Azure data movement and transformation capabilities (Azure Data Factory, Data Lake Analytics, Data Bricks, Stream Analytics)
Knowledge of Talend ETL
Microsoft related certifications such as the MCSD/MCSE
City:
State:
Community / Marketing Title: Data Engineer
Company Profile:
About AIS
AIS, Dedicated to Our People

AIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee’s success; however, they define it.

It’s our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP).

Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.

We hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.

We Invest in Individuals Committed to Innovation

AIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals. We are looking for:

Smart people with a passion for technology
Strong technical capabilities with a consultancy mindset
Close involvement with local technical communities
A willingness to think outside of the box to provide innovative solutions to clients
Ability to solve challenging technical business problems
Self-directed professionals
Our Core Values
Client Success
Continued Learning and Technical Excellence
Strong Client Relationships
Citizenship and Community
AIS is an Equal Opportunity Employer
Location_formattedLocationLong: Chevy Chase, Maryland US
CountryEEOText_Description: Applied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status or any other basis covered by law. Employment decisions are based solely on qualifications merit, and business need.",data engineer
"YOUR LIFE'S MISSION: POSSIBLE


You have goals, dreams, hobbies and things you’re passionate about.

What’s Important to You Is Important to Us
We’re looking for people who not only want to do meaningful, challenging work, keep their skills sharp and move ahead, but who also take time for the things that matter to them—friends, family and passions. And we're looking for team members who are passionate about our mission—making a difference in military members' and their families' lives. Together, we can make it happen.

Don’t take our word for it.
FORTUNE 100 Best Companies to Work For®
Computerworld® Best Places to Work in IT
FORTUNE® Best Workplaces for Millennials
Forbes® America’s Best Employers
IND123

Basic Purpose


Salary Range: $120,000 - $215,000

Remote Work Policy: Remote work is available for all positions contingent on business need and manager discretion

Benefits Package: Best-in-Class Benefits! (7% 401k match / Pension plan / Tuition reimbursement / Great insurance options)

Responsibilities:

Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platformsEvaluate and define functional requirements for BI and DW solutionsDefine and build data integration processes to be used across the organizationBuild conceptual and logical data models for stakeholders and managementAnalyze and validate data accuracy of report resultsWork directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectivesPrepares realistic project implementation plans which highlight major milestones and deliverables leveraging standard methods and work planning toolsRecognizes potential issues and risks during the analytics project implementation and can suggest realistic mitigation strategiesCoaches and mentors project team members in carrying out analytics project implementation activitiesLeads the preparation of high quality project deliverables that are valued by the business and presents them in such a manner that they are easily understood by project stakeholdersInterpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision makingUse of statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future eventsThe ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise mannerThe ability to define and analyze models that predict the probability of an outcomeOffers improvements to the way in which analytics service the entire functionCommunicating and owning the process in manipulating and merging large datasetsAbility to view and understand other project or functional areas in order to consolidate analytical needs and processesBeing a key point of contact between the data analyst/data scientist and the project/functional analytics leadsPerform other duties as assigned

Qualifications and Education Requirements:

Bachelor's degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience5 years’ experience working in a cloud computing with Azure experience requiredExperience with data migration to cloud based environmentExtensive 5 years of experience in providing data architecture solutions for Cloud applicationsKnowledge of and the ability to perform basic statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniquesExperienced in the use of standard ETL tools and techniquesExperienced in sourcing, maintaining, and updating dataUnderstanding of data warehousing, data cleaning, data pipelines and other analytical techniques required for data usageDemonstrates functional knowledge of data visualization tools such as Microsoft Power BI, TableauHas working knowledge of various data structures and the ability to manipulate data within visualization toolsAbility to manipulate raw data into effective visualization dashboardsAbility to communicate end to end data outcomes visuallyDemonstrates a deep understanding of multiple database conceptsHas a working knowledge of various data structures and the ability to extract data from various data sources (such as Cognos, Informatica)Understands the concepts and application of data mapping and building requirementsOptimal understanding of SQL

Desired Qualifications and Education Requirements:

Graduate education in Information Systems, Computer Science, Engineering, or related fieldKnowledge of Navy Federal Credit Union instructions, standards, and procedures

Hours: Monday - Friday, 8:00am - 4:30pm

Location: 820 Follin Lane, Vienna, VA 22180

Equal Employment Opportunity


Navy Federal values, celebrates, and enacts diversity in the workplace. Navy Federal takes affirmative action to employ and advance in employment qualified individuals with disabilities, disabled veterans, Armed Forces service medal veterans, recently separated veterans, and other protected veterans. EOE/AA/M/F/Veteran/Disability

Disclaimer

Navy Federal reserves the right to fill this role at a higher/lower grade level based on business need. An assessment may be required to compete for this position.

Bank Secrecy Act

Remains cognizant of and adheres to Navy Federal policies and procedures, and regulations pertaining to the Bank Secrecy Act.

Employee Referrals

This position is eligible for the TalentQuest employee referral program. Please indicate the employee who referred you when applying.",data engineer
"Who We Seek:Passion Seekers. You genuinely care about the work that you do and its impact on society.Self-Starters. You’re a go-getter who isn’t afraid to step up and disrupt the status quo.Entrepreneurs. You bring fresh ideas to the table, work hard, develop business and consistently seek new challenges.Collaborators. You’re a great contributor to a high performing team that accomplishes great feats for our clients.What You Will Do:Work with data and analytics experts to strive for greater functionality in our data systems.Establish performance monitoring of databases and create data pipeline architectureManage data life cycle from transactions to reporting to archival of dataBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologiesIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Required Skills:5 years of proven expertise in relational and dimensional data modelling5 years in modern data development, upgrading, support and design.Proven experience in leading data teams on data migration and transformationExperience in establishing performance and statistical monitoring of enterprise databases to include, but not limited to; wellness checks, data integrity, privacy and security scans.Experience in supporting cloud database environments, specifically AWS (i.e., EC2, S3, Neptune or Redshift) to include backup and archiving of data.Good to have experience with data lakes implementationsShould be able to work early morning hours i.e. 6 am to 2 pm (US Eastern Time) for at least 2-3 days a weekDesired Skills:Experience with Apache NiFi is desiredExperience with OpenText Captiva is desired.Years of Experience: 5Minimum Education Required: Bachelor’s DegreeDue to Federal Requirements, only U.S. Citizens will be considered100% Remote CapabilityAbout Us:Attain is a place for great ideas and the people who have them. As a digital solutions, management, and strategy consulting firm, our professionals provide innovative solutions to revolutionize government, education, health, and nonprofit organizations and positively impact those they serve. We are business analysts, technologists, digital strategists, managers of change, and forward thinkers, with the entrepreneurial drive to shape the future. With a nationwide presence, our team is in 40 states and the District of Columbia. Visit www.attain.com/careers to explore your path forward with Attain.Attain is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.Job Type: Full-timePay: $113,001.00 - $135,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceFlexible scheduleHealth insurancePaid time offTuition reimbursementVision insuranceSchedule:Monday to FridayEducation:Bachelor's (Preferred)Experience:AWS Cloud: 3 years (Preferred)This Job Is Ideal for Someone Who Is:Detail-oriented -- would rather focus on the details of work than the bigger pictureAutonomous/Independent -- enjoys working with little directionInnovative -- prefers working in unconventional ways or on tasks that require creativityThis Company Describes Its Culture as:Innovative -- innovative and risk-takingOutcome-oriented -- results-focused with strong performance culturePeople-oriented -- supportive and fairness-focusedCompany's website:https://www.attain.com/about-attainWork Remotely:Yes",data engineer
"Requirements:
Responsible for the design and development of voice, video, radio-frequency, and/or data communications networks.
Provides expert level analysis of data communications networks, including planning, designing, evaluating, selecting, and upgrading operating systems and protocol suites and configuring communication media with concentrators, bridges, and other devices.
Plans network layouts and configures systems to user environments.
Analyzes network topologies and traffic and capacity requirements.
Supports the acquisition of hardware and software as well as subcontractor services as needed.
May provide technical support and troubleshooting to users.
May perform network administration duties.
Provides guidance and work leadership to less-experienced network personnel and may have supervisory responsibilities.
Serves as technical team or task leader.
Maintains current knowledge of relevant technology as assigned.
Participates in special projects as required.
Powered by JazzHR
0BFKTvDoqQ",data engineer
"3+ years of experience as a Data Engineer or in a similar roleExperience with data modeling, data warehousing, and building ETL pipelinesExperience in SQLBachelor’s degree in Engineering, Statistics, Computer Science, Mathematics or related fieldExtensive SQL and database skills with ability to deep dive into data logicExperience RDBMS databases like MySQL/SQL Server/Oracle and MPP Databases like Redshift, Teradata or NetezzaExperience with programming languages such as Java, PySpark/Scala, Python, etc.Excellent data presentation skills and demonstrated ability to successfully partner with business and technical teamsExperience in gathering requirements and formulating business metrics for reporting

The Accounting BI team supports the global Accounting organization with process automation/improvements, developing automated reporting solutions/tools, and improving the ability of the accounting organization to process, analyze, access and consume accurate and timely financial data. The team supports the global accounting organization and partners closely with accountants and financial analysts supporting the various businesses and industries Amazon operates in.

Our ideal candidate thrives in a fast-paced environment, relishes working with large transactional volumes and big data, enjoys the challenge of highly complex business contexts (that are typically being defined in real-time) and, above all, is passionate about data and analytics.

Responsibilities of this position include:
Working with stakeholders and other engineering teams to identify and scope the right data architecture and technology to be used to facilitate analysis of most common Amazon customer behavioral questions.Partnering with partner engineering teams to enhance data infrastructure, data availability, and broad access to customer insights made available through BI tools across the organization.Design, build and implement the right ETL processes using AWS and similar technologies.Implement anomaly detection systems to have a proactive approach to any potential data quality issues, using industry standard frameworks.Enable large scale analytics using EMR and other big data technologies.Establishing and implementing technology best practices that should be followed across the organization.Work on proof of concepts for adoption of new technology and tools.

Masters in computer science, mathematics, statistics, economics, or other quantitative fields.Experience with Big data tools like Kinesis or Kafka ,SparkKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",data engineer
"Overview:

Amify is a four-time Inc. Magazine award-winning Amazon strategy partner, focused on maximizing the potential of brands on Amazon. Amify uses industry expertise and a data-driven approach to monitor, optimize, and enhance product listings, protect brands from unauthorized sellers and price violations, and drive sales through advertising. With tact, innovation, and a dedication to brand authenticity, Amify has emerged as one of the largest brand partners on Amazon.
This is a unique opportunity to get in on the ground floor of a rapidly-growing and well-funded technology startup in an incredibly hot space.
We are seeking a data engineer to help design, architect and implement the next generation of our multi-platform service. You’ll work with cutting-edge technologies, be given as much responsibility as you can handle, and contribute to and grow with an experienced and dynamic team.
Responsibilities:

Oversee Amify data architecture
Lead and implement data strategy across 50+ disparate systems used to
operate the Amify business
Oversee and implement intelligent, optimized use of Snowflake
Implement operational and analytical schemas in support of business and
strategy
Implement best practices for traceability, quality, and security of data
Investigate and implement algorithms to improve insights into data
Qualifications:

Technical Requirements
Expert in SQL
Demonstrated skill in at least one enterprise-capable database,
e.g. Snowflake, Postgres, Oracle, Mysql, etc.
Fluent in at least one ETL/ELT toolsuite, e.g. dbt/fivetran, Matillion,
Informatica, etc.
Fluent in at least one BI toolsuite, e.g. Looker, Tableau, Domo, etc.
Fluent in at least one scripting language such as node.js, unix
shell/bash/zsh/etc, python, PL/SQL, etc.
Fluent in the principles of programming for example in JavaScript/node.js,
Java, Python, Ruby, C#, Rust, Go, Scala, Clojure, etc.
Qualifications
3-5 years of relevant professional experience
Self starter: bias towards action and getting things done
Fast learner: passion and curiosity to explore and embrace new ideas and
new technologies.
Attention to detail, analytical mindset
Trustworthy, Team-Oriented, Transparent
Excellent written and verbal skills",data engineer
"Job Responsibility:
Provides technical support for data services and data management in a multi-cloud and multi-domain environment and supports technical and transition planning for transitions applications, services and data sets to the ICITE suite of shared services.
Develops recommendations for Data formats and develops solutions for data ingest and automated queries.
Assists other senior consultants with analyses and evaluations and with the preparation of recommendations for data management improvements and optimization.

Qualifications:
Experience with information systems architecture, automation, communications protocols, and modeling and simulation.
3+ of commensurate data engineering experience
Minimum a bachelors degree in a related field.
TS/SCI",data engineer
"Do you like designing and developing geospatial and applications across multiple disciplines? Do you have a background and interest in solutions design and sales engineering? New Light Technologies Inc. (NLT), a research and technology firm based in Washington DC, is currently seeking a Geospatial Consultant with expertise in configuration and deployment of the latest ESRI GIS platforms to perform implementation consulting and sales engineering services. The candidate will work with our growing company to design, build, and maintain platforms and applications that focus on geospatial information, data science, visualization, and communication of disaster-related data, focused on the ESRI suite of products. This position requires a strong voice and willingness to work with a diverse and dynamic customer base spanning multiple fields including education, natural disasters, healthcare, and international development. Strong background in sales engineering in the GIS industry with particular expertise in the ESRI suite is required. Expertise and familiarity with other GIS technology suits is preferred but not required.Qualifications:Bachelor’s degree in geography, geosciences, business, computer science, or equivalent practical experience in a sales engineering role.Sales engineering and implementation consulting experience including a demonstrated background in product/solution design, presentation, and demonstration capabilities to existing prospective customers.Experience designing impactful presentations and pitches that have led to new clients or projects.Rapid prototyping experience for demonstration of capabilities to prospective customer objectives and goals.Ability to design and deploy end-to-end ESRI geospatial technology stack implementations.Familiarity and experience with the full cycle of product developmentExperience and familiarity with a variety of geospatial data formatsAbility to work independently and with groupsExperience with scripting languages such as JavaScript, Python, etc.Bonus Skills:Experience with open-source solutions such as QGIS, GeoNode or other GIS suites.Experience with Google Earth EngineExperience analyzing and maintaining large imagery datasetsKnowledge of cloud environments (GCP, AWS, Azure)About the company:New Light Technologies Inc., based in Washington DC, provides comprehensive information technology solutions for clients in government, commercial, and non-profit sectors including extensive experience in public safety & emergency management, transportation, urban planning, demographics & economics, environmental studies, telecommunications, healthcare, and other fields. NLT specializes in DevOps enterprise-scale systems development, management, and staffing and offers unique capabilities in Cloud & IT Infrastructure Modernization, Mobile Computing, Cybersecurity, Big Data Development, Modeling & Analytics, Geospatial Information Systems, and the Development of High-Performance Web-based Visualization Solutions.Job Types: Full-time, Part-time, Temporary, Internship, ContractPay: $80,000.00 - $110,000.00 per yearBenefits:401(k)Dental InsuranceEmployee Assistance ProgramEmployee DiscountFlexible ScheduleFlexible Spending AccountHealth InsurancePaid Time OffParental LeaveProfessional Development AssistanceReferral ProgramRetirement PlanVision InsuranceSchedule:Monday to FridayOn CallWeekendsCOVID-19 considerations:Most of our work is done remotely especially during the COVID-19 Pandemic with occasional visits to customers locations where there is a need for physical access to servers is required.Work authorization:United States (Required)Application Question:Please list any presentations, repos, or other online content that is publicly available if you have them. For proper consideration, please make sure to take our skills tests in this indeed posting.Security Clearance Required:Confidential (Preferred)Contract Length:2 months or less3 - 4 months5 - 6 months7 - 11 months1 yearMore than 1 yearVariesContract Renewal:LikelyWork Location:One locationMultiple locationsFully RemoteOn the roadHours per week:Less than 1010-1920-2930-39This Company Describes Its Culture as:Detail-oriented -- quality and precision-focusedInnovative -- innovative and risk-takingOutcome-oriented -- results-focused with strong performance culturePeople-oriented -- supportive and fairness-focusedTeam-oriented -- cooperative and collaborativeCompany's website:https://NewLightTechnologies.comBenefit Conditions:Waiting period may applyOnly full-time employees eligibleWork Remotely:Yes",data engineer
"Data Engineer
Location: Washington DC or Remote
Job ID: 1149
**Active Secret or Top-Secret clearance required
If we ask you to explain your day and you use phrases like dimensional data modeling, data movement and storage, enterprise analytics, data pipelines, shaping data for presentation, or database querying, then we should talk.
We need creative problem solvers that can come up with creative solutions when working with the client. We are technology agnostic, in a sense, and are interested in people who come from different environments and backgrounds then perhaps what we have seen. Understanding and having an interest in front-end analytics and visualizations is a great skill to have as well.
You can be a self-proclaimed analytics guru, advancing in your BI career, or an Application Developer who has a strong interest in data. As long as you have strong knowledge and hands-on experience with SQL you could be a fit for this role.

You will be part of one of our fastest growing, heavily impactful teams, and working with a great client who loves data as much as we do.
Knowledge, Skills & Abilities
Strong SQL
Experience with ETL tools
Experience with Reporting/Analytics tools (MicroStrategy, Tableau, PowerBI, Cognos, Busines Objects, etc.) is a plus
Data manipulation & analysis
Unstructured data management
Experience with Cloud Technologies (S3, Redshift, lambda, AWS, etc.) is a plus
Qualifications Required
Bachelor’s Degree in Statistics, Mathematics, Computer Science, Management Information Systems, Engineering, Business Analytics disciplines, or related area
3+ years of experience with ETL and data integration, data quality analysis, statistical analysis and/or modeling
Active Secret or Top-Secret US Government clearance
Benefits
Compensation plan consisting of a competitive base salary and an uncapped bonus
100% Health coverage for employees with Vision and Dental options
Paid holidays and vacation with a generous leave policy
Commute reimbursement
Professional development and educational tuition assistance
Flexible spending account options
401(k) retirement plan with complimentary financial advisory services
Datastrong’s culture
Our culture is built on inclusion, collaboration, high performance, and opportunity. That combination helps our professionals make a difference individually and collectively. And it makes Datastrong a rewarding place to work. We are continuously looking for new ways to maintain a culture where our people excel and lead healthy, happy lives.
Corporate citizenship
We are proud to be part of the communities where we work and live. Datastrong takes great pride in knowing that what we do best – applying our skills and experience – helps to build strong communities that shape and sustain our business culture. Our team members are provided opportunities to support the community through volunteerism, giving their time, talent, and generosity.

Datastrong is committed to hiring and retaining a diverse workforce. We are an Equal Opportunity and Affirmative Action Employer, making decisions without regard to race, color, religion, sex, national origin, age, veteran status, disability, or any other protected class. If accommodation is needed in the application process, arrangements can be made with the local regional office.",data engineer
"Marathon is seeking a Data Engineer to support the data pipeline for the development and integration of Artificial Intelligence and Big Data/Cloud Solutions.The candidate will have experience in managing, manipulating, storing and parsing data in a data pipeline for variety of computer vision and other AI applications. The work is performed in a multidisciplinary team environment in an agile project framework. The candidate must be highly motivated and enthusiastic about implementing new technologies in a small team environment where deadlines are important to national security.Position Responsibilities:Work closely with data engineers and architects to engineer ETL solutions to prepare for ingest into machine learning development environmentsDesign, develop and maintain data services and/or pipelines as part of an Agile/Scrum teamCode, test and implement ETL logicSupport continuous process automation for data ingestSupport the development and integration of Client algorithms for testing and operational deploymentPerform data analysis to assist in decision-makingWork with program management and engineers to implement and document complex and evolving requirementsPerform multiple tasks simultaneously and successful perform under changing requirements and deadlinesHelp cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamworkRequired Skills:Must be a US Citizen and Secret Clearance eligibleA Bachelor's Degree in Data Science, Math, Finance, Statistics, Information Management, Computer Science, Engineering, or equivalent field2-7+ years of hands-on work experience in one of the related areas: Data Science, Computer Science or Computer EngineeringProficient parsing / ETL-ing data into a variety of formats for Client applications, Test & Validation, metrics derivationProficiency with Python, Linux shell and scripting languagesTechnical proficiency with transforming structured and unstructured data setsExcellent communication, and presentation skills with the demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences with an impeccable attention to detailDesired Skills:Secret Clearance and eligible to obtain Top SecretAdvanced degree (Masters) in a technical disciplineExperience working with cloud technologies (Amazon Web Services, Microsoft Azure, etc.)Experience working with Department of Defense (DoD) organizations or performersExperience with PySpark, PandasExperience with Palantir FoundryExperience with NoSQL databases such as MongoDBJob Type: Full-timePay: $120,000.00 - $150,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceFlexible scheduleHealth insuranceLife insurancePaid time offTuition reimbursementVision insuranceSchedule:8 hour shiftExperience:python & pyspark: 1 year (Preferred)hadoop, hive, impala: 1 year (Preferred)hadoop: 1 year (Preferred)big data: 1 year (Preferred)python: 1 year (Preferred)Application Question:Do you have a SECRET CLEARANCE?This Job Is:A job for which military experienced candidates are encouraged to applyWork Remotely:Temporarily due to COVID-19",data engineer
"Bachelor's degree in Engineering, Statistics, Computer Science, or a related quantitative field1+ years of experience in a data engineering position or similarExperience with SQL, data warehousing and OLAP technologiesDesign and scripting experience in Python, Java, etc.

At Amazon, we're working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright, and visionary people. AWS Demand Planning is seeking a Data Engineer with a combination of superior analytical abilities, business acumen, business judgement, curiosity, technical skills, and written and verbal communication skills to join our team.

Data-driven decision-making is at the core of Amazon’s culture and people who are exceptionally talented at building data infrastructures to support reporting and analytics needs of the business are critical. Your work will directly impact the decisions and strategy of the entire AWS Demand Planning team and our customers. As an Amazon Data Engineer, you will be working in one of the world's largest data warehouse environments. This environment processes millions of time series events each week to build and test models for generating forecasts for all AWS services. These models and forecasts will be used in business reporting solutions that are consumed by thousands of users worldwide to optimize service availability and infrastructure costs. Your data solutions will be supporting the growth of one of the world’s largest Cloud.

An ideal candidate will have excellent communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. You should be able to demonstrate an expertise in designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing applications. You should be able to work with business customers in a fast-paced environment by understanding their business requirements and implementing reporting solutions. You will also gain an understanding of Supply Chain Management for the Cloud and develop a deep understanding of the internal workings of all AWS Services. Your role will leverage AWS technologies such as Lambda, Glue, and Kinesis to craft data solutions. The successful candidate will not only possess the expertise and passion for data, and build tools to solve for business challenges, but also will interact directly with business leaders and teams to answer important business questions and drive change.

The data engineer must be a self-starter, comfortable with ambiguity, able to think big and be creative (while still paying careful attention to detail), and enjoy working in a fast-paced, dynamic environment. If you are excited about data and results-oriented, and want to join a growing analytics team within Amazon - this role is for you!

The primary responsibilities of this role include:
Working with managers, software developers, BI engineer and scientists to design and develop data infrastructure to support the growth of AWS.Enabling effective decision making by retrieving and aggregating data from multiple sources and compiling it into digestible and actionable forms.Performing deep-dives to find root causes of variances in data between different sources.Writing high quality SQL to create and store large data sets.Developing a deep understanding of our vast data sources and identify which to use to solve specific business problems.Optimizing the performance of business-critical queries and dealing with ETL job related issues.Tuning application and query performance using SQL.Identifying the data quality issues across the various platforms at Amazon.

Master’s degree or higher in Engineering, Statistics, Computer Science, or an equivalent quantitative field3+ years of experience working as a data engineer in a business environmentExperience with AWS services like S3, Redshift, Athena, RDS, Lambda etc.Experience communicating results and business impact of analytical deep dives to senior leadershipExperience working in a technology companyExperience with BI data visualization and delivery tools such as Power BI, Tableau, Qlik, Quicksight, etc.
Amazon is committed to a diverse and inclusive workforce. Amazon is an equal opportunity employer and does not discriminate on the basis of race, ethnicity, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",data engineer
"What You Will Do:

I. General Summary
Under limited direction, responsible for design and implementation of core technologies associated with the organizations data analysis and analytics technical infrastructure. As a core member of a high-performance team, ensure data pipelines are consistently and reliably maintained and analytics capabilities are delivered at an optimum level, helping the organization identify insights from a large number of diverse datasets.
II. Principal Responsibilities and Tasks
The following statements are intended to describe the general nature and level of work being performed by people assigned to this classification. These are not to be construed as an exhaustive list of all job duties performed by personnel so classified.
1. Ensure analytics infrastructure and associated systems meet business requirements and industry best practices.
2. Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.
3. Gathers, analyzes, documents and translates application requirements into data models.
4. Builds data models.
5. Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.
6. Researches and proposes opportunities for data acquisition and new uses for existing data.
7. Codes, tests, and documents new or modified data systems to create robust and scalable applications for analytics.
8. Expands and grows data platform capabilities to solve new data problems and challenges.
9. Creates data flow diagrams for business systems.
10. Builds automation tools; ensures all automated processes preserve data by managing the alignment of data availability and integration processes.
11. Performs technology and product research to better define requirements, resolve important issues and improve the overall capability of the technology stack.
12. Contributes to the design and direction of enterprise-wide data architecture as well as design documentation deliverables.
13. Supports standardization of documentation and the adoption of standards and practices related to data and applications.
14. Develops Relational Data Models, Dimensional Data Models, Data Dictionary and Metadata.
15. Develop data set processes for data mining and production.
16. Working both independently and in collaboration with our data integration developers, data scientists, designs and builds high-performance algorithms, prototypes, predictive models and proof of concepts.

17. Works closely with our developer team to integrate innovative algorithms into our production systems.
18. Supports business decisions with ad hoc analysis as needed.

What You Need to Be Successful:

III. Education and Experience
1. Bachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.
2. Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.
3. Previous experience and knowledge in programming or scripting languages. (e.g., C/C++, Python, Ruby) is required.
4. Experience with agile or other rapid application development methods is required.
5. Experience with object-oriented design, coding and testing patterns as well as experience in engineering software platforms and large-scale data infrastructures is required.
6. Experience and understanding of Big Data technologies, Analytics & Visualization is preferred. Two or more years' experience in Enterprise Data Integration is also preferred.
IV. Knowledge, Skills and Abilities
1. Knowledge of data analysis, end user requirements analysis, and business requirements analysis to develop a clear understanding of the business needs and to incorporate these needs into technical solutions.
2. Strong knowledge of and experience with data mapping and ETL (Extract Transform Load) concepts.
3. Significant knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.
4. Working knowledge of relational, document oriented or object oriented databases, such as PostgreSQL, Oracle, Cache, SQL, and MongoDB.
5. Deep knowledge in data mining, machine learning or natural language processing.
6. Strong programming experience to clean and scrub noisy datasets; experience building parameterized scripts/programs and automation ideally using python or java
7. Experience with Hortonworks or the Hadoop ecosystem in general, including HDSF and such tools as Spark, MapReduce, Pig and Hive. Experience with Ranger / Atlas and /or Falcon would be useful.
8. Experience with various messaging systems, such as ActiveMQ or RabbitMQ is preferred. Experience with web development frameworks such as Django would also be preferred.
10. Must work well in a high-performance team environment.
We are an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",data engineer
"What You Will Do:

I. General Summary
Under limited direction, responsible for design and implementation of core technologies associated with the organizations data analysis and analytics technical infrastructure. As a core member of a high-performance team, ensure data pipelines are consistently and reliably maintained and analytics capabilities are delivered at an optimum level, helping the organization identify insights from a large number of diverse datasets.
II. Principal Responsibilities and Tasks
The following statements are intended to describe the general nature and level of work being performed by people assigned to this classification. These are not to be construed as an exhaustive list of all job duties performed by personnel so classified.
1. Ensure analytics infrastructure and associated systems meet business requirements and industry best practices.
2. Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.
3. Gathers, analyzes, documents and translates application requirements into data models.
4. Builds data models.
5. Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.
6. Researches and proposes opportunities for data acquisition and new uses for existing data.
7. Codes, tests, and documents new or modified data systems to create robust and scalable applications for analytics.
8. Expands and grows data platform capabilities to solve new data problems and challenges.
9. Creates data flow diagrams for business systems.
10. Builds automation tools; ensures all automated processes preserve data by managing the alignment of data availability and integration processes.
11. Performs technology and product research to better define requirements, resolve important issues and improve the overall capability of the technology stack.
12. Contributes to the design and direction of enterprise-wide data architecture as well as design documentation deliverables.
13. Supports standardization of documentation and the adoption of standards and practices related to data and applications.
14. Develops Relational Data Models, Dimensional Data Models, Data Dictionary and Metadata.
15. Develop data set processes for data mining and production.
16. Working both independently and in collaboration with our data integration developers, data scientists, designs and builds high-performance algorithms, prototypes, predictive models and proof of concepts.

17. Works closely with our developer team to integrate innovative algorithms into our production systems.
18. Supports business decisions with ad hoc analysis as needed.

What You Need to Be Successful:

III. Education and Experience
1. Bachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.
2. Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.
3. Previous experience and knowledge in programming or scripting languages. (e.g., C/C++, Python, Ruby) is required.
4. Experience with agile or other rapid application development methods is required.
5. Experience with object-oriented design, coding and testing patterns as well as experience in engineering software platforms and large-scale data infrastructures is required.
6. Experience and understanding of Big Data technologies, Analytics & Visualization is preferred. Two or more years' experience in Enterprise Data Integration is also preferred.
IV. Knowledge, Skills and Abilities
1. Knowledge of data analysis, end user requirements analysis, and business requirements analysis to develop a clear understanding of the business needs and to incorporate these needs into technical solutions.
2. Strong knowledge of and experience with data mapping and ETL (Extract Transform Load) concepts.
3. Significant knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.
4. Working knowledge of relational, document oriented or object oriented databases, such as PostgreSQL, Oracle, Cache, SQL, and MongoDB.
5. Deep knowledge in data mining, machine learning or natural language processing.
6. Strong programming experience to clean and scrub noisy datasets; experience building parameterized scripts/programs and automation ideally using python or java
7. Experience with Hortonworks or the Hadoop ecosystem in general, including HDSF and such tools as Spark, MapReduce, Pig and Hive. Experience with Ranger / Atlas and /or Falcon would be useful.
8. Experience with various messaging systems, such as ActiveMQ or RabbitMQ is preferred. Experience with web development frameworks such as Django would also be preferred.
10. Must work well in a high-performance team environment.
We are an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",data engineer
"Overview:

Amify is a four-time Inc. Magazine award-winning Amazon strategy partner, focused on maximizing the potential of brands on Amazon. Amify uses industry expertise and a data-driven approach to monitor, optimize, and enhance product listings, protect brands from unauthorized sellers and price violations, and drive sales through advertising. With tact, innovation, and a dedication to brand authenticity, Amify has emerged as one of the largest brand partners on Amazon.
This is a unique opportunity to get in on the ground floor of a rapidly-growing and well-funded technology startup in an incredibly hot space.
We are seeking a data engineer to help design, architect and implement the next generation of our multi-platform service. You’ll work with cutting-edge technologies, be given as much responsibility as you can handle, and contribute to and grow with an experienced and dynamic team.
Responsibilities:

Oversee Amify data architecture
Lead and implement data strategy across 50+ disparate systems used to
operate the Amify business
Oversee and implement intelligent, optimized use of Snowflake
Implement operational and analytical schemas in support of business and
strategy
Implement best practices for traceability, quality, and security of data
Investigate and implement algorithms to improve insights into data
Qualifications:

Technical Requirements
Expert in SQL
Demonstrated skill in at least one enterprise-capable database,
e.g. Snowflake, Postgres, Oracle, Mysql, etc.
Fluent in at least one ETL/ELT toolsuite, e.g. dbt/fivetran, Matillion,
Informatica, etc.
Fluent in at least one BI toolsuite, e.g. Looker, Tableau, Domo, etc.
Fluent in at least one scripting language such as node.js, unix
shell/bash/zsh/etc, python, PL/SQL, etc.
Fluent in the principles of programming for example in JavaScript/node.js,
Java, Python, Ruby, C#, Rust, Go, Scala, Clojure, etc.
Qualifications
3-5 years of relevant professional experience
Self starter: bias towards action and getting things done
Fast learner: passion and curiosity to explore and embrace new ideas and
new technologies.
Attention to detail, analytical mindset
Trustworthy, Team-Oriented, Transparent
Excellent written and verbal skills",data engineer
"3+ years of Data Center Facilities Infrastructure Experience, including knowledge of network design and layout (copper / fiber) as well as low / high voltage (copper/ fiber) cabling, BMS Systems, EPMS, access control, monitoring and alarming systems.3+ years of Data Center Engineering to include researching, developing and writing equipment and design layouts/specifications of server rooms, MDFs, IDFs, rackable equipment, and other modular or containerized IT infrastructure solution.Knowledge of Data Center Facilities such as generators, chillers, cooling towers, air handling units, UPS, electrical sub distribution systems, fire detection and suppression systems, cable reticulation systems3+ years of experience as an electrical and/or mechanical engineering technician in critical environments with remote networked device monitoring.Bachelor’s Degree or Technical (Military/ Trade School) Degree and relevant experience.3+ years of Data Center or Campus Infrastructure support experience.Strong verbal and written communication skills with attention to clarity and detail.Ability to prioritize work and stay organized in complex, fast-paced environment with high levels of ambiguity. Work both independently and as part of a group.Functional knowledge of layer 2 networking concepts (Cisco CCENT equivalent).Functional competency in MS Windows and/or Linux operating systems.

External job description

The Amazon IT Services team is continuing to build out its Infrastructure Engineering team, which globally supports Amazon Web Services (AWS) sites worldwide. Infrastructure Engineers work to improve and expand a suite of offerings to meet the needs of the ever-changing and every-growing AWS business. You will work closely with delivery teams to drive execution of improvements, but you will also be integral to design, coordination, and tactical thinking.

AWS IT Services is looking for candidates with strong technical infrastructure backgrounds, passionate about learning every day, who get a strong sense of satisfaction out of delighting customers by solving problems. The ideal candidate is passionate about flexibility in design, engineering excellence, and providing cost-effective solutions with an eye to the future. You understand the challenges associated with deploying infrastructure at scale and foresee the integration issues that may come up. Our mission is to design systems and platforms that set the global standard for performance, availability, security, and cost, enabling AWS site business needs. The work you do locally will influence processes globally. Data center Infrastructure Engineer will:

Define and manage standards, processes, Change Management, Life Cycle replacement for Environment monitoring devices, UPS and PDUs.Serve as a subject matter expert while working with partner teams and vendors to install, troubleshoot, repair, and lifecycle manage in-rack Environment Monitoring devices/PDU/UPS hardware within IDFs and MDFs.Assess, document, and communicate the needs of internal customers to the appropriate stakeholders. Estimate costs, level of effort, timelines, dependencies, and alternatives. Deliver solutions within your direct control and facilitate solutions owned by others.Work on continuous improve their level of knowledge about the business and relevant technologies.Maintain positive and collaborative working relations with partner teams, vendors, teammates, and internal customers.
BASIC QUALIFICATIONS

3+ years of Data Center Facilities Infrastructure Experience, including knowledge of network design and layout (copper / fiber) as well as low / high voltage (copper/ fiber) cabling, BMS Systems, EPMS, access control, monitoring and alarming systems.3+ years of Data Center Engineering to include researching, developing and writing equipment and design layouts/specifications of server rooms, MDFs, IDFs, rackable equipment, and other modular or containerized IT infrastructure solution.Knowledge of Data Center Facilities such as generators, chillers, cooling towers, air handling units, UPS, electrical sub distribution systems, fire detection and suppression systems, cable reticulation systems3+ years of experience as an electrical and/or mechanical engineering technician in critical environments with remote networked device monitoring.Bachelor’s Degree or Technical (Military/ Trade School) Degree and relevant experience.3+ years of Data Center or Campus Infrastructure support experience.Strong verbal and written communication skills with attention to clarity and detail.Ability to prioritize work and stay organized in complex, fast-paced environment with high levels of ambiguity. Work both independently and as part of a group.Functional knowledge of layer 2 networking concepts (Cisco CCENT equivalent).Functional competency in MS Windows and/or Linux operating systems.
PREFERRED QUALIFICATIONS

Background in Electrical Engineering, Mechanical Engineering or relevant disciplineExcellent verbal and written communication skillsStrong analytical skills with demonstrated problem solving abilityEager to learn, enjoy a fast paced environmentDriven to provide the best customer experience via technologyVendor management experienceAbility to drive innovation in the spaceCCNA or equivalent experience.Project/Program Management experienceProcess Improvement/ Operational Excellence experience
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.

Background in Electrical Engineering, Mechanical Engineering or relevant disciplineExcellent verbal and written communication skillsStrong analytical skills with demonstrated problem solving abilityEager to learn, enjoy a fast paced environmentDriven to provide the best customer experience via technologyVendor management experienceAbility to drive innovation in the spaceCCNA or equivalent experience.Project/Program Management experienceProcess Improvement/ Operational Excellence experience",data engineer
"Overview:

LMI is a consultancy dedicated to powering a future-ready, high-performing government, drawing from expertise in digital and analytic solutions, logistics, and management advisory services. We deliver integrated capabilities that incorporate emerging technologies and are tailored to customers’ unique mission needs, backed by objective research and data analysis. Founded in 1961 to help the Department of Defense resolve complex logistics management challenges, LMI continues to enable growth and transformation, enhance operational readiness and resiliency, and ensure mission success for federal civilian and defense agencies.

This position is located at a client site in Washington, DC.
Responsibilities:

The ideal candidate will have direct, applied experience with one or more of the following areas:

Develop data structures and systems to support the generation of business insights
Knowledge and experience in overall ETL processes
Maintain data infrastructure and develop scripts for regular processes
Define, design, and develop data flow diagrams, data dictionaries, and logical and physical models
Define data requirements, document data elements, and capture and maintain metadeta
Identify and clean incomplete, incorrect, inaccurate or irrelevant data
Identify new opportunities to use data to improve business performance
Communicate and present data by developing reports using Tableau or Business Intelligence tools
Adhere to compliance and audit requirements for data storage, architecture, cybersecurity, etc.
Qualifications:
Bachelor’s degree in a quantitative field (e.g., engineering, statistics, mathematics, information technology, etc.) is preferred.
Must have at least 2 years of experience, preferably with a federal government customer.
Experience with big data tools: Hadoop, Spark, Kafka
Experience with relational SQL and NoSQL databases: Postgres, Cassandra, MongoDB
Experience with data governance tools: Collibra, Immuta
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala
Must possess strong written and verbal communication skills.
#LI-SH1
EEO Statement:

LMI is an Equal Opportunity Employer-all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.",data engineer
"Marathon is seeking a Data Engineer to support the data pipeline for the development and integration of Artificial Intelligence and Big Data/Cloud Solutions.The candidate will have experience in managing, manipulating, storing and parsing data in a data pipeline for variety of computer vision and other AI applications. The work is performed in a multidisciplinary team environment in an agile project framework. The candidate must be highly motivated and enthusiastic about implementing new technologies in a small team environment where deadlines are important to national security.Position Responsibilities:Work closely with data engineers and architects to engineer ETL solutions to prepare for ingest into machine learning development environmentsDesign, develop and maintain data services and/or pipelines as part of an Agile/Scrum teamCode, test and implement ETL logicSupport continuous process automation for data ingestSupport the development and integration of Client algorithms for testing and operational deploymentPerform data analysis to assist in decision-makingWork with program management and engineers to implement and document complex and evolving requirementsPerform multiple tasks simultaneously and successful perform under changing requirements and deadlinesHelp cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamworkRequired Skills:Must be a US Citizen and Secret Clearance eligibleA Bachelor's Degree in Data Science, Math, Finance, Statistics, Information Management, Computer Science, Engineering, or equivalent field2-7+ years of hands-on work experience in one of the related areas: Data Science, Computer Science or Computer EngineeringProficient parsing / ETL-ing data into a variety of formats for Client applications, Test & Validation, metrics derivationProficiency with Python, Linux shell and scripting languagesTechnical proficiency with transforming structured and unstructured data setsExcellent communication, and presentation skills with the demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences with an impeccable attention to detailDesired Skills:Secret Clearance and eligible to obtain Top SecretAdvanced degree (Masters) in a technical disciplineExperience working with cloud technologies (Amazon Web Services, Microsoft Azure, etc.)Experience working with Department of Defense (DoD) organizations or performersExperience with PySpark, PandasExperience with Palantir FoundryExperience with NoSQL databases such as MongoDBJob Type: Full-timePay: $120,000.00 - $150,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceFlexible scheduleHealth insuranceLife insurancePaid time offTuition reimbursementVision insuranceSchedule:8 hour shiftExperience:python & pyspark: 1 year (Preferred)hadoop, hive, impala: 1 year (Preferred)hadoop: 1 year (Preferred)big data: 1 year (Preferred)python: 1 year (Preferred)Application Question:Do you have a SECRET CLEARANCE?This Job Is:A job for which military experienced candidates are encouraged to applyWork Remotely:Temporarily due to COVID-19",data engineer
"We have an immediate need for a software QA engineer that will help our technical solutions team monitor every phase of the software development process and help the team develop, execute, and maintain industry standard compliance measures. The ideal candidate has a strong background in software development and programming. He or she will have an enhanced facility with the Windows and/or iOS operating systems and associated hardware. The ideal candidate is a hard-working individual who has a creative but analytical mindset. He or she should be self-motivated and self-supervised, as this job can be a remote position. The position comes with opportunities for advancement within the IT department for the right candidate as well as exceptional benefits and a competitive salary.Responsibilities:Software planning and design  * Writing and reviewing code  * Estimating, prioritizing, planning, and coordinating all QA activity  * Designing and deploying testing processes  * Developing, tracking, and improve QA metrics  * Ensuring the timely completion and deployment of software  * Overseeing software integrations  * Creating a plan and processes for release management  * Ensuring compliance with in-house QA guidelines and relevant legislation related to data use and protection  * Monitoring feedback and QA outcomes  * Analyzing and enhancing the QA methodology to deliver more efficient QA processes  * Tracking and managing the deployment of solutions for customer-facing software  * Report issues and concerns immediately to relevant stakeholdersDesired SkillsBachelor’s Degree in Computer Science, Computer Programming or related field  * Proficiency in PHP, C++ (familiarity/proficiency in other languages a plus)  * Proficiency in Java and/or Swift (Objective-C also acceptable)  * 4+ years’ software development experience  * In depth understanding of SQL Server, HTML, CSS  * Advanced knowledge of Windows operating systems and Microsoft software  * Advanced knowledge of iOS operating systems and Apple software  * Knowledge of Javascript / JQuery  * Ability to focus on multiple projects at once and to troubleshoot problems quickly  * Commitment to continuing education in computer programming (training at employer’s expense)Job Type: Full-timePay: $34.00 - $42.00 per hourBenefits:401(k)401(k) matchingDental insuranceDisability insuranceFlexible scheduleHealth insuranceLife insurancePaid time offTuition reimbursementSchedule:Monday to FridaySupplemental Pay:Bonus payExperience:Test Automation: 4 years (Preferred)Software Testing: 4 years (Preferred)Work Location:Fully RemoteThis Job Is Ideal for Someone Who Is:Dependable -- more reliable than spontaneousAdaptable/flexible -- enjoys doing work that requires frequent shifts in directionDetail-oriented -- would rather focus on the details of work than the bigger pictureAchievement-oriented -- enjoys taking on challenges, even if they might failAutonomous/Independent -- enjoys working with little directionCompany's website:www.cdcaexams.orgBenefit Conditions:Waiting period may apply",data engineer
"Job Responsibility:
Provides technical support for data services and data management in a multi-cloud and multi-domain environment and supports technical and transition planning for transitions applications, services and data sets to the ICITE suite of shared services.
Develops recommendations for Data formats and develops solutions for data ingest and automated queries.
Assists other senior consultants with analyses and evaluations and with the preparation of recommendations for data management improvements and optimization.

Qualifications:
Experience with information systems architecture, automation, communications protocols, and modeling and simulation.
3+ of commensurate data engineering experience
Minimum a bachelors degree in a related field.
TS/SCI",data engineer
"The DevOps Engineer will be responsible for designing, implementing and supporting DevOps solutions for the Joint Polar Satellite System (JPSS) Common Ground System (CGS) program, a state-of-the-art ground station for the next generation of low earth orbiting environment satellites. This system provides global coverage, monitors environment conditions, collects, disseminates and processes data about the Earth’s Weather, Atmosphere, Oceans, Land, and Near-Space environment.The ideal candidate will join the Infrastructure IPT and collaborate with HW&I to understand and implement best practices, participate and periodically lead small teams, execute trade studies, prototypes and operational deployments, mentor team members, create metrics and prepare and present status to leadership.Responsibilities Include:Leverage company best practices and capabilities to assist programs with deployment, implementation, modernization and support of DevSecOps software solutionsSupport software tool customization and automation including deployment of templates, dashboards and scripts to support program needsAssist engineering teams with development and support of build/test pipeline and integration, optimizing for performance and scalability across both cloud and on premise computing environmentsProvide guidance on software engineering tool hardware infrastructure resource requirementsAssist engineers with tool usage and issues, leveraging standards and best practicesProvide guidance on engineering tool hardware infrastructure resource requirementRequired Skills:Direct experience with different Project Management methodologies (Scrum, Waterfall, Kanban, Agile)Advanced experience with Containerization and Orchestration (Docker, Kubernetes, OpenShift)Experience with DevOps philosophiesExperience deploying and supporting CI/CD tooling, pipelines and automation solutions in a business/enterprise environmentExperience provisioning cloud-based infrastructure such as AWSExperience using Configuration Management processes - Version Control of software and applications using ClearCase, Gitlab, Artifactory and familiarity with Defects, Change Requests and Help Desk tickets using ClearQuest or JiraExperience implementing code/artifact control tools such as ClearCase, Gitlab, Artifactory including branching best practicesExperience with the architecture and design of COTS Infrastructure (IT)Experience with Windows and/or Linux System AdministrationScripting skills (i.e. PowerShell, Python, Ruby, bash, etc.)General working knowledge of networks, storage, and virtualizationThe ability to effectively plan their own work and the work of others on the teamThe ability to work independently, without much supervision, and ensure project goals are metProven analytical skills with the ability to troubleshoot complex tool and system operation performance issues with services and devices spanning multiple network boundariesExperience in technical leadership and mentoring team membersAbility to prepare and present status, plans, and risks to managementDesired Skills:Background in COTS/FOSS product installation, configuration and integrationExpert level skill with Kubernetes and containersExpert level skill with automation tools such as Chef (preferred), Puppet, Ansible, TerraformRequired Education:Requires a degree in Science, Technology, Engineering or Mathematics (STEM) from a Nationally Accredited Educational Institution and 6+ years of related work experience.Job Types: Full-time, ContractPay: $74.00 - $90.00 per hourSchedule:Monday to FridayExperience:US Citizenship: 1 year (Required)DevOps: 5 years (Required)Contract Renewal:LikelyFull Time Opportunity:YesWork Location:One locationCompany's website:www.cornerstonetek.comWork Remotely:Temporarily due to COVID-19",data engineer
"Data Engineer
Location: Washington DC or Remote
Job ID: 1149
**Active Secret or Top-Secret clearance required
If we ask you to explain your day and you use phrases like dimensional data modeling, data movement and storage, enterprise analytics, data pipelines, shaping data for presentation, or database querying, then we should talk.
We need creative problem solvers that can come up with creative solutions when working with the client. We are technology agnostic, in a sense, and are interested in people who come from different environments and backgrounds then perhaps what we have seen. Understanding and having an interest in front-end analytics and visualizations is a great skill to have as well.
You can be a self-proclaimed analytics guru, advancing in your BI career, or an Application Developer who has a strong interest in data. As long as you have strong knowledge and hands-on experience with SQL you could be a fit for this role.

You will be part of one of our fastest growing, heavily impactful teams, and working with a great client who loves data as much as we do.
Knowledge, Skills & Abilities
Strong SQL
Experience with ETL tools
Experience with Reporting/Analytics tools (MicroStrategy, Tableau, PowerBI, Cognos, Busines Objects, etc.) is a plus
Data manipulation & analysis
Unstructured data management
Experience with Cloud Technologies (S3, Redshift, lambda, AWS, etc.) is a plus
Qualifications Required
Bachelor’s Degree in Statistics, Mathematics, Computer Science, Management Information Systems, Engineering, Business Analytics disciplines, or related area
3+ years of experience with ETL and data integration, data quality analysis, statistical analysis and/or modeling
Active Secret or Top-Secret US Government clearance
Benefits
Compensation plan consisting of a competitive base salary and an uncapped bonus
100% Health coverage for employees with Vision and Dental options
Paid holidays and vacation with a generous leave policy
Commute reimbursement
Professional development and educational tuition assistance
Flexible spending account options
401(k) retirement plan with complimentary financial advisory services
Datastrong’s culture
Our culture is built on inclusion, collaboration, high performance, and opportunity. That combination helps our professionals make a difference individually and collectively. And it makes Datastrong a rewarding place to work. We are continuously looking for new ways to maintain a culture where our people excel and lead healthy, happy lives.
Corporate citizenship
We are proud to be part of the communities where we work and live. Datastrong takes great pride in knowing that what we do best – applying our skills and experience – helps to build strong communities that shape and sustain our business culture. Our team members are provided opportunities to support the community through volunteerism, giving their time, talent, and generosity.

Datastrong is committed to hiring and retaining a diverse workforce. We are an Equal Opportunity and Affirmative Action Employer, making decisions without regard to race, color, religion, sex, national origin, age, veteran status, disability, or any other protected class. If accommodation is needed in the application process, arrangements can be made with the local regional office.",data engineer
"ECS is seeking a Data Engineer – Intermediate to work in our Washington D.C. office.
Job Description:
Work in data warehouse environment, which includes data design, database architecture, metadata and repository creation.
Translate business needs into long-term architecture solutions.
Define, design, and build databases for Oracle, Postgres, dynamo, and SQL/NoSQL.
Develop data warehousing blueprints, evaluating hardware and software platforms, and integrating systems.
Evaluate reusability of current data for additional analyses.
Review object and data models and the metadata repository to structure the data for better management and quicker access.

Required Skills:
Must have a Top-Secret Clearance with SCI Eligibility
Computer Science MS w/2 years exp or BS with 4 years exp
Must have expertise in developing in a micro service environment
Must be able to demonstrate working knowledge of Agile Scrum methodology
2 years of experience with SQL and NoSQL database technology
Experience with Extract, Transform and Load (ETL) tasks
Must have a Cloud Certified Developer – Associate certification

Desired Skills:
Statistics and modeling experience
Experience with Git
Willingness to learn new skills and technologies on the fly
Ability to communicate with customers to refine requirements
Ability to deconstruct customer requirements into delineated tasks
Being a team player

ECS is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. ECS promotes affirmative action for minorities, women, disabled persons, and veterans.
ECS is a leading mid-sized provider of technology services to the United States Federal Government. We are focused on people, values and purpose. Every day, our 3000+ employees focus on providing their technical talent to support the Federal Agencies and Departments of the US Government to serve, protect and defend the American People.",data engineer
"The role

As a Data Engineer at Blue State, you'll play an integral role on a smart and vibrant analytics team servicing a wide range of progressive organizations. You'll design, build, and manage the systems and processes which form the underpinning of Blue State's analytics work, supporting and working alongside data analysts and campaign strategists. But you'll also work directly with Blue State's clients to help solve their data integrity and integration challenges, serving as a trusted advisor to your counterparts within client organizations.

Day-to-day responsibilities:

Create and support systems and processes for managing, compiling, manipulating, and analyzing data for client and internal projects
Work with Blue State's client organizations to solve difficult data migration, management, and integration challenges
Build data pipelines, data warehouses, reporting dashboards, automated exports, and synchronization processes
Automate workflows and look for further opportunities to improve efficiency in our work
Always maintain a high level of data security and privacy
The team

You will be a part of the global Web and Product Development team working primarily with our creative agency on client projects. You'll work in either the NY or DC office.

Top things we're looking for
Good foundational understanding of statistical analysis
Extensive experience working with SQL databases in an analytics or business intelligence context
Familiarity with common marketing technology platforms like Google Analytics, Google Ads, Facebook Ads, email marketing tools, and other marketing automation tools
Experience with ETL/ELT tools, processes, and best practices
Strong Python experience:
Python should be your go-to tool for solving problems. If the first thing you want to do when you have to do the same thing twice is write a Python script to automate it - we want you!
Experience with task automation in a Python context - experience with AirFlow, Prefect, Dask a big plus
Experience working with restful APIs - you can competently navigate unfamiliar API documentation and figure out how to accomplish tasks
Strong working knowledge of Google BigQuery and the Google Cloud Platform data product ecosystem including:
Designing data warehouse schemas for cross-channel marketing analytics
Utilizing the suite of Google Cloud Platform tools for the purposes of extracting, processing, manipulating and analysing data
Building and running automated tasks within the GCP environment - e.g. Cloud Compute, Cloud Functions, Cloud Run, Cloud Scheduler
Comfortable managing GCP IAM policies across projects and teams
Comfortable working within a spreadsheet (even if you prefer a database) - preferably in Google Sheets - bonus points if you've extended Google Sheets using Google Apps Script
Familiarity with Git and maintains good habits around code maintenance
Able to build repeatable and well-documented processes and tools that can be used by other technically-savvy but non-Python developer analytics team members (think easy to use command-line scripts - not GUIs)
Good at teaching others what you know.
The company

Blue State is the purpose-driven creative and tech agency for brands and causes looking to inspire people to take action. With clients including the AARP, Google, UNICEF, JDRF, and Colgate. Blue State cultivates communities, builds platforms, and transforms how organizations engage their most important people. Led by some of the most creative and analytical minds from the political, nonprofit, and brand worlds, Blue State is a part of WPP and has more than 150 employees across five offices.",data engineer
"Overview:

In today’s rapidly evolving technology landscape, an organization’s data has never been a more important aspect in achieving mission and business goals. Our data exploitation experts work with our clients to support their mission and business goals by creating and executing a comprehensive data strategy using the best technology and techniques given the challenge.

At Steampunk, our goal is to build and execute a data strategy for our clients to coordinate data collection and generation, to align the organization and its data assets in support of the mission, and ultimately to realize mission goals with the strongest effectiveness possible.

For our clients, data is a strategic asset. For the our client, they are looking to become a facts-based, data-driven, customer-focused organization. To help realize this goal, they are leveraging visual analytics platforms to analyze, visualize, and share information. At steampunk you will design and develop on a next-generation Visual Analytics and Collaboration suite.
Contributions:

We are looking for seasoned Data Engineer to work with our existing Data Exploitation team to develop Strategies and then deliver results. We are looking for a more than just a ""Data Engineer"", but a technologist with excellent communication and customer service skills and a passion for data.
Profile and analyze source system data to determine data relationships, keys, conformed dimensions, and necessary transformations
Identify data quality issues
Ensure data structures are designed for flexibility to support clients' business needs
Develop strategy and repeatable process for maintaining Enterprise Data Models
Design & test integrations to/from data modeling tools
Work with developers to create an API access layer for the data
Reverse engineer complex, new datasets, and map these new datasets to the existing model.
Provide documentation and instruction to data modelers and developers
Constantly interact with both ETL developers and end users data analysts to share knowledge, collect feedback, and provide additional implementation requirements.
Develop, maintain, and review data processes and architecture for both on-premise and cloud-based data systems
You will contribute to the growth of our Data Exploitation Practice.
Who wants to do something different......
Qualifications:
US Citizen Only
Ability to hold a position of public trust with the US government.
5+ years industry experience coding commercial software and a passion for solving complex problems.
5+ years direct experience in Data Engineering with experience in tools such as:
Advanced working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience manipulating, processing and extracting value from large, disconnected datasets.
Experience manipulating structured and unstructured data for analysis
Experience constructing complex queries to analyze results using databases or in a data processing development environment
Experience with data modeling tools and process
Experience architecting data systems (transactional and warehouses)
Experience aggregating results and/or compiling information for reporting from multiple datasets
Experience working in an Agile environment
Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models
About steampunk:

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",data engineer
"Job Functions: Analyze system requirements and design responsive algorithms and solutionsUse big data and cloud technologies to produce production quality codeEngage in performance tuning and scalability engineeringWork with team, peers and management to identify objectives and set prioritiesPerform related SDLC engineering activities like sprint planning and estimationWork effectively in small agile teamsProvide creative solutions to problemsIdentify opportunities for improvement and executeEssential skills: Experience with cloud based Big Data technologiesProficiency in Hive / Spark SQLExperience with SparkExperience with one or more programming languages like Scala, Python, and/or JavaAbility to push the frontier of technology and independentlyJob Type: ContractSchedule:Monday to FridayEducation:Bachelor's (Preferred)Experience:Hive/Spark SQL: 8 years (Preferred)Big Data Technologies: 8 years (Preferred)Java/Python/Scala: 6 years (Preferred)",data engineer
"· Bachelor's degree in a quantitative/technical field (e.g. Computer Science, Economics, Finance, Mathematics, Statistics, Engineering) ·
1-2 years of relevant experience in one of the following areas: data science, data engineering, business intelligence or business analyticsAdvanced experience with SQL (query optimization, data modeling, data processing (ETL/ELT) and analytical functions)Experience using business intelligence reporting tools (Tableau, Looker, Microstrategy, OBIEE, Cognos, Quicksight, etc.)Ability to communicate effectively (verbally/written) with technical and non-technical stakeholders at various levels, from operational roles to executive leadership.Demonstrated ability to navigate ambiguous requests and manage multiple competing priorities, prioritizing effectively and independently in a fast-paced environment

We are looking for a highly analytical Business Intelligence Engineer to join Amazon’s Global Accounting Business Intelligence and Analytics team.

The Accounting BI team supports the global Accounting organization with process automation/improvements, developing automated reporting solutions/tools, and improving the ability of the accounting organization to process, analyze, access and consume accurate and timely financial data. The team supports the global accounting organization and partners closely with accountants and financial analysts supporting the various businesses and industries Amazon operates in.

The ideal candidate thrives in a fast-paced environment, relishes working with ambiguity, big data, and enjoys the challenges of highly complex business context. This role requires an individual with excellent analytical abilities, deep knowledge of business intelligence solutions, and the ability to quickly learn, adapt and work with a variety of technologies.

Specific responsibilities include:
Collaboration and partnership with Accounting and software development teams driving enterprise level projectsContributing to the design, development, and maintenance of multiple scalable solutions supporting internal/external global stakeholdersCoordinating project prioritization with multiple stakeholders, managing and executing competing priorities from end to end within defined timelinesSupporting the global accounting organization with various ad-hoc reporting, analyses, and data processing needs

Master’s degree in Computer Science, Engineering, Math, Finance, Statistics or related disciplineExperience with and detailed knowledge of data warehouse architecture, data processing (ETL/ELT) and production/development environmentsExperience with scripting languages (R or Python) supporting automation, data manipulation and basic mathematical computations
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",data engineer
"About UsFIA Tech is a dynamic and growing Software-as-a-Service technology company which supports over 700 global finance and trading firms. Our customers depend on our technology and solutions which connect the global futures and derivatives industry for trade processing and regulatory compliance.OverviewFIA Tech is seeking a Technical Support Engineer to join our high energy team during a period of exciting growth and change. We are looking for a great technologist and communicator that can successfully explain intricate technical information to any non-technical user. The ideal candidate for this role is positive, curious, and enjoys problem solving. The role will start out as a remote position but will eventually transition work out of our Washington D.C. office, with occasional travel to our other offices and data centers.Responsibilities: · Provide Tier 1 and 2 support for all corporate devices, including laptops, desktops, printers, and IP and mobile phones. Responsible for their troubleshooting, repairs, network connectivity, VPN access, and remote installation of software and applications· Create, maintain, and deploy desktop and server virtual machine images.· Manage user and group policy objects across multiple MS Active Directory domains and MS O365, including creating and modifying GPO’s, user accounts, groups, and file and share permissions.· Maintain and keep up to date build and configuration documentation, and software installation procedures in Confluence and SharePoint· Responsible for managing and deploying desktop patching and security updates· Assist the Technical Operation staff with various infrastructure projectsPosition Requirements: Must possess a High School Diploma; years of experience can be used in lieu of a degreeMinimum of two years of experience in a desktop support role in a MS Windows 7/10 enterprise environmentStrong troubleshooting and communication skills to diagnose, document and resolve technical issuesThis position is part of the on-call support rotation, and may require after hours and weekend workMust be able to lift up to 50lbs if/when the need arisesExposure and knowledge of the following technologies is a plus:MS server and Linux OSEnterprise patching and remote software deploymentTelephony and VOIP systemsBasic understanding of monitoring and alerting softwareBackup and Restore software and proceduresAntivirus and treat remediation softwareVMWare, virtualization, and VDICloud technologiesFIA Tech is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.Job Type: Full-timePay: $60,000.00 - $75,000.00 per yearBenefits:401(k)401(k) matchingDental insuranceDisability insuranceEmployee assistance programEmployee discountFlexible spending accountHealth insuranceLife insurancePaid time offParental leaveReferral programVision insuranceSchedule:8 hour shiftSupplemental Pay:Bonus payWork Remotely:Temporarily due to COVID-19",data engineer
